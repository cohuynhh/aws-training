<a id="top" />

# AWS FAQs Summary

## Content
* [FAQs ACM (Amazon Certificate Manager)](#faqs-acm)
* [FAQs Cognito](#faqs-cognito)
* [FAQs WorkSpaces](#faqs-workspaces)
* [FAQs DynamoDB](#faqs-dynamodb)
* [FAQs IAM](#faqs-iam)
* [FAQs API GW](#faqs-api-gw)
* [FAQs SES](#faqs-ses)
* [FAQs CloudFormation](#faqs-cloud-formation)
* [FAQs Kinesis](#faqs-kinesis)
* [FAQs Trusted Advisor](#faqs-trusted-advisor)
* [FAQs SQS](#faqs-sqs)
* [FAQs SNS](#faqs-sns)
* [FAQs OpsWorks](#faqs-opsworks)
* [FAQs Route 53](#faqs-route-53)

## FAQs ACM
**Amazon Certificate Manager**
<p align="right"><a href="#top">Top</a></p>

* To use an ACM certificate with Amazon CloudFront, you must request the certificate in the US East (N. Virginia) region. ACM certificates in this region that are associated with a CloudFront distribution are distributed to all the geographic locations configured for that distribution.
* **Can I use certificates on Amazon EC2 instances or on my own servers?**  
  No.
* **Does ACM support checking of DNS Certificate Authority Authorization (CAA) records?**  
  Yes. DNS Certificate Authority Authorization (CAA) records allow domain owners to specify which certificate authorities are authorized to issue certificates for their domain. When you request an ACM Certificate, AWS Certificate Manager looks for a CAA record in the DNS zone configuration for your domain. If a CAA record is not present, then Amazon can issue a certificate for your domain. Most customers fall into this category. If your DNS configuration contains a CAA record, that record must specify one of the following CAs before Amazon can issue a certificate for your domain: amazon.com, amazontrust.com,
* **Q: Does ACM support checking of DNS Certificate Authority Authorization (CAA) records?**  
  Yes. DNS Certificate Authority Authorization (CAA) records allow domain owners to specify which certificate authorities are authorized to issue certificates for their domain. When you request an ACM Certificate, AWS Certificate Manager looks for a CAA record in the DNS zone configuration for your domain. If a CAA record is not present, then Amazon can issue a certificate for your domain. Most customers fall into this category. If your DNS configuration contains a CAA record, that record must specify one of the following CAs before Amazon can issue a certificate for your domain: amazon.com, amazontrust.com, awstrust.com, or amazonaws.com.
* **Q. Why does ACM use CNAME records for DNS validation instead of TXT records?**  
  Using a CNAME record allows ACM to renew certificates for as long as the CNAME record exists. The CNAME record directs to a TXT record in an AWS domain (acm-validations.aws) that ACM can update as needed to validate or re-validate a domain name, without any action from you.
* **Q: Does ACM provide Organizational Validation (OV) or Extended Validation (EV) certificates?**  
  Not at this time. Q: Does ACM provide certificates for anything other than SSL/TLS for websites? Not at this time. Q: Can I use certificates provided by ACM for code signing or email encryption? No.
* **Q: How do I revoke a certificate?**  
  You can request ACM to revoke a certificate by visiting the AWS Support Center and creating a case.
* ACM certificates are only copied across Regions if the certificate is associated with a CloudFront distribution. In that case, CloudFront distributes the ACM certificate to the geographic locations configured for your distribution.
* **Q: Can I audit the use of certificate private keys?**  
  Yes. Using AWS CloudTrail you can review logs that tell you when the private key for the certificate was used.
* **Q: What is the validity period for certificates provided by ACM?**  
  Certificates provided by ACM are currently valid for 13 months.
* **Q: Does ACM allow local language characters in domain names, otherwise known as Internationalized Domain Names (IDNs)?**  
  ACM does not allow Unicode encoded local language characters; however, ACM allows ASCII-encoded local language characters for domain names.
* **Q: Will I be notified before my certificate is renewed and the new certificate is deployed?**  
  No. ACM may renew or rekey the certificate and replace the old one without prior notice.
* **Q: Does my site drop existing connections when ACM deploys the renewed certificate?**  
  No, connections established after the new certificate is deployed use the new certificate, and existing connections are not affected.

## FAQs Cognito
<p align="right"><a href="#top">Top</a></p>

* Cognito Identity also enables you to customize workflows by, for example, adding app-specific logic to user registration for fraud detection and user validation through AWS Lambda.
* **Q: Can I have my own identity provider to support user sign-up and sign-in?**  
  Yes, you can easily and securely add sign-up and sign-in functionality to your apps with Cognito Identity. Your users can sign-up and sign-in using email, phone number, or user name. You can also implement enhanced security features, such as email verification, phone number verification, and multi-factor authentication. Cognito Identity also enables you to customize workflows by, for example, adding app-specific logic to user registration for fraud detection and user validation through AWS Lambda. To learn more, visit our docs.
* **Q: Do I still need my own backend authentication systems with Cognito Identity?**  
  No. Cognito Identity supports login through Amazon, Facebook, Twitter, Digits, and Google, as well as providing support for unauthenticated users. With Cognito Identity you can support federated authentication, profile data sync store and AWS access token distribution without writing any backend code.
* **Q: Does Cognito Identity support separate identities for different users on the same device?**  
  Yes. Cognito Identity supports separate identities on a single device, such as a family iPad. Each identity is treated separately and you have complete control over how your app logs users in and out and how local and remote app data is stored.
* **Q: How much does Cognito Identity cost?**  
  With Amazon Cognito, you pay only for what you use. There are no minimum fees and no upfront commitments. If you are using the Cognito Identity to create a User Pool, you pay based on your monthly active users (MAUs) only. A user is counted as a MAU if within a calendar month there is an identity operation related to that user, such as sign-up, sign-in, token refresh, and password change. You are not charged for subsequent sessions or for inactive users with in that calendar month. Separate charges apply for optional use of SMS messaging as described below. The Your User Pool feature has a free tier of 50,000 MAUs each month. The Cognito Identity free tier does not expire at the end of your 12 month AWS Free Tier term, and it is available to both existing and new AWS customers indefinitely Federated Identities and secure access control for AWS resources are always free with Cognito Identity.
* **Q: Does every write or read from the app count as a sync operation?**  
  No. You decide when to call the synchronize() method. Every write or read from the device is to the local SQlite store. This way you are in complete control of your costs.
* **Q: Is data saved directly to the Amazon Cognito sync store?**  
  No. The optional AWS Mobile SDK saves your data to an SQLite database on the local device, this way the data is always accessible to your app. The data is pushed to the Amazon Cognito sync store by calling the synchronize() method and, if push synchronization is enabled, all other devices linked to an identity are notified of the data change in the sync store via Amazon SNS.

## FAQs WorkSpaces
<p align="right"><a href="#top">Top</a></p>

* **Q: Can I migrate users from an Amazon WorkSpaces Windows 7 bundle to a Windows 10 bundle?**  
  No. To offer existing users a Windows 10 desktop experience, you need to delete their existing Amazon WorkSpace and create a new one using a Windows 10 WorkSpaces bundle. To migrate data and documents, we recommend that you use the sync feature available with Amazon WorkDocs. Note that Amazon WorkDocs comes with 50GB of free storage for every Amazon WorkSpace.
* **Q: What does a user need to use an Amazon Workspace?**  
  A user needs to have an Amazon WorkSpace provisioned for them, and a broadband Internet connection. To use an Amazon WorkSpaces client application to access their WorkSpace, they will need a supported client device (PC, Mac, iPad, Kindle Fire, or Android tablet), and an Internet connection with TCP ports 443 & 4172, and UDP port 4172 open.
* **Q: If I am located a significant distance from the region where my Amazon WorkSpace is located, will I have a good user experience?**  
  If you are located more than 2000 miles from the regions where Amazon WorkSpaces is currently available, you can still use the service, but your experience may be less responsive. The easiest way to check performance is to use the Amazon WorkSpaces Connection Health Check Website. You can also refer to the Regional Products and Services page for details of Amazon WorkSpaces service availability by region.
* **Q: Will encryption impact the launch time of an Amazon WorkSpace?**  
  The launch time of a WorkSpace that only requires user volume encryption are similar to those of an unencrypted WorkSpace. The launch time of a WorkSpace that requires root volume encrypt will take several more minutes.
* **Q: What is the Amazon WorkDocs sync client?**  
  The Amazon WorkDocs sync client is a client application that you can install on your Amazon WorkSpace, which continuously, automatically, and securely syncs documents from your Amazon WorkSpace to your Amazon WorkDocs location. You can also install the Amazon WorkDocs sync client on a Mac or PC to sync documents across all desktops they may be using. When an Amazon WorkSpace is launched, users will have a link on their desktop so that they can install the Amazon WorkDocs sync client. The client can be downloaded here
* **Q: How do I upload my applications to Amazon WAM?**  
  You can package your applications using the Amazon WAM Studio, validate using the Amazon WAM Player, and then upload your applications to Amazon WAM. For more information, see the Amazon WAM User Guide on packaging and validating.
* **Q: Can I use any other client (e.g., an RDP client) with Amazon WorkSpaces?**  
  No. You can use any of the free clients provided by AWS,
* **Q: Can I use PCoIP Zero Clients with Amazon WorkSpaces?**  
  Yes, Amazon WorkSpaces supports PCoIP Zero Client devices that have the Teradici Tera2 chipset. For a complete list of Zero Clients that are compatible with Amazon WorkSpaces please visit the device finder here (site hosted by Teradici).
* **Q: Can I use the built in microphone and speakers for making audio calls?**  
  Yes.
* **Q: Which web browsers can I use to access Amazon WorkSpaces Web Access?**  
  Amazon WorkSpaces Web Access works with Google Chrome version 53 and higher, and Firefox version 49 and higher, running on Windows, Mac, or Linux. Mobile versions of Chrome and Firefox are not currently supported.
* **Q: What languages are supported by Amazon WorkSpaces?**  
  Amazon WorkSpaces bundles that provide the Windows 7 and Windows 10 desktop experience currently support English (US) and Japanese. You can also download and install language packs for Windows directly from Microsoft. For more information, visit this page. Amazon WorkSpaces client applications currently support English (US), German, Chinese (Simplified), Japanese, French Canadian, Korean, and Portuguese.
* **Q: Can I provide more than one Amazon Workspace per user?**  
  No. You can currently only provide one WorkSpace for each user.
* **Q: What is the network bandwidth that I need to use my Amazon WorkSpace?**  
  The bandwidth needed to use your WorkSpace depends on what you're doing on your WorkSpace. For general office productivity use, we recommend that a bandwidth download speed of between 300Kbps up and 1Mbps. For graphics intensive work we recommend bandwidth download speeds of 3Mbps.
* **Q: What is the maximum network latency recommended while accessing a Workspace?**  
  While the remoting protocol has a maximum round trip latency recommendation of 250 ms, the best user experience will be achieved at less than 100 ms.
* **Q: What does the Amazon WorkSpaces Application Manager (Amazon WAM) cost?**  
  Amazon WAM is available in two versions - lite or standard. The Amazon WAM lite subscription is available at no charge, and the Amazon WAM standard subscription costs $5/user/month. You can learn more about Amazon WAM here.
* **Q: What is included with the Amazon WorkSpaces Free Tier?**  
  The WorkSpaces Free Tier includes two Standard bundle Amazon WorkSpaces, for 40 hours of combined use per month, for two calendar months. As with all bundles, your WorkSpace comes with Internet Explorer 11, Mozilla Firefox, and 7-Zip pre-installed, and access to Amazon WorkDocs with 50 GB included storage.
* Understanding Your Usage with Billing Reports.
* **Q: Can I connect Amazon WorkSpaces to my VPC?**  
  Yes. The first time you connect to the WorkSpaces Management Console, you can choose an easy ‘getting started’ link that will create a new VPC and two associated subnets for you as well as an Internet Gateway and a directory to contain your users. If you choose to access the console directly, you can choose which of your VPCs your WorkSpaces will connect to. If you have a VPC with a VPN connection back to your on-premises network, then your WorkSpaces will be able to communicate with your on-premises network (you retain the usual control you have over network access within your VPC using all of the normal configuration options such as security groups, network ACLS, and routing tables).
* **Q: Will I be able to monitor how many hours my Amazon WorkSpaces have been running?**  
  Yes, you will be able to monitor the total number hours your Amazon WorkSpaces has been running in a given period of time through Amazon CloudWatch “UserConnected” metric.
* **Q: Can I print from my tablet or Chromebook?**  
  The Amazon WorkSpaces clients for tablets and Chromebook support cloud printing services including, but not limited to, Cortado ThinPrint® and Google Cloud Print. Local and network printing are not currently supported.

## FAQs DynamoDB
<p align="right"><a href="#top">Top</a></p>

* Based on what we see in typical database workloads, we believe that the total bill for using SSD-based DynamoDB will usually be lower than the cost of using a typical spinning media-based relational or nonrelational database. If you need to store a large amount of data that you rarely access, DynamoDB may not be right for you. We recommend that you use Amazon S3 for such use cases. You also should note that the storage cost reflects the cost of storing multiple copies of each data item across multiple facilities in an AWS Region.
* **Q: How does Amazon DynamoDB differ from Amazon SimpleDB?**  
  Which should I use? Both services are non-relational databases that remove the work of database administration. Amazon DynamoDB focuses on providing seamless scalability and fast, predictable performance. It runs on solid state disks (SSDs) for low-latency response times, and there are no limits on the request capacity or storage size for a given table. This is because Amazon DynamoDB automatically partitions your data and workload over a sufficient number of servers to meet the scale requirements you provide. In contrast, a table in Amazon SimpleDB has a strict storage limitation of 10 GB and is limited in the request capacity it can achieve (typically under 25 writes/second); it is up to you to manage the partitioning and re-partitioning of your data over additional SimpleDB tables if you need additional scale. While SimpleDB has scaling limitations, it may be a good fit for smaller workloads that require query flexibility. Amazon SimpleDB automatically indexes all item attributes and thus supports query flexibility at the cost of performance and scale. Amazon CTO Werner Vogels' DynamoDB blog post provides additional context on the evolution of non-relational database technology at Amazon.
* **Q: How does Amazon DynamoDB differ from Amazon SimpleDB?**  
  Which should I use? Both services are non-relational databases that remove the work of database administration. Amazon DynamoDB focuses on providing seamless scalability and fast, predictable performance. It runs on solid state disks (SSDs) for low-latency response times, and there are no limits on the request capacity or storage size for a given table. This is because Amazon DynamoDB automatically partitions your data and workload over a sufficient number of servers to meet the scale requirements you provide. In contrast, a table in Amazon SimpleDB has a strict storage limitation of 10 GB and is limited in the request capacity it can achieve (typically under 25 writes/second); it is up to you to manage the partitioning and re-partitioning of your data over additional SimpleDB tables if you need additional scale. While SimpleDB has scaling limitations, it may be a good fit for smaller workloads that require query flexibility. Amazon SimpleDB automatically indexes all item attributes and thus supports query flexibility at the cost of performance and scale. Amazon CTO Werner Vogels' DynamoDB blog post provides additional context on the evolution of non-relational database technology at Amazon.
* **Q: Is there a limit on the number of attributes an item can have?**  
  There is no limit to the number of attributes that an item can have. However, the total size of an item, including attribute names and attribute values, cannot exceed 400KB.
* If you wish to exceed throughput rates of 10,000 writes/second or 10,000 reads/second, you must first contact Amazon through this online form
* **Q. Can I force an Auto Scaling policy to scale up to maximum capacity or scale down to minimum capacity instantly?**  
  No, scaling up instantly to maximum capacity or scaling down to minimum capacity is not supported. Instead, you can temporarily disable Auto Scaling, set desired capacity you need manually for required duration, and re-enable Auto Scaling later.
* **Q. Where can I monitor the scaling actions triggered by Auto Scaling?**  
  You can monitor status of scaling actions triggered by Auto Scaling under the 'Capacity' tab in the management console and from CloudWatch graphs under the 'Metrics' tab.
* **Q: What are global secondary indexes?**  
  Global secondary indexes are indexes that contain a partition or partition-and-sort keys that can be different from the table's primary key. For efficient access to data in a table, Amazon DynamoDB creates and maintains indexes for the primary key attributes. This allows applications to quickly retrieve data by specifying primary key values. However, many applications might benefit from having one or more secondary (or alternate) keys available to allow efficient access to data with attributes other than the primary key. To address this, you can create one or more secondary indexes on a table, and issue Query requests against these indexes. Amazon DynamoDB supports two types of secondary indexes: Local secondary index — an index that has the same partition key as the table, but a different sort key. A local secondary index is "local" in the sense that every partition of a local secondary index is scoped to a table partition that has the same partition key. Global secondary index — an index with a partition or a partition-and-sort key that can be different from those on the table. A global secondary index is considered "global" because queries on the index can span all items in a table, across all partitions. Secondary indexes are automatically maintained by Amazon DynamoDB as sparse objects. Items will only appear in an index if they exist in the table on which the index is defined. This makes queries against an index very efficient, because the number of items in the index will often be significantly less than the number of items in the table. Global secondary indexes support non-unique attributes, which increases query flexibility by enabling queries against any non-key attribute in the table. Consider a gaming application that stores the information of its players in a DynamoDB table whose primary key consists of UserId (partition) and GameTitle (sort). Items have attributes named TopScore, Timestamp, ZipCode, and others. Upon table creation, DynamoDB provides an implicit index (primary index) on the primary key that can support efficient queries that return a specific user’s top scores for all games. However, if the application requires top scores of users for a particular game, using this primary index would be inefficient, and would require scanning through the entire table. Instead, a global secondary index with GameTitle as the partition key element and TopScore as the sort key element would enable the application to rapidly retrieve top scores for a game. A GSI does not need to have a sort key element. For instance, you could have a GSI with a key that only has a partition element GameTitle. In the example below, the GSI has no projected attributes, so it will just return all items (identified by primary key) that have an attribute matching the GameTitle you are querying on.
* **Q: Does the local version of DynamoDB support global secondary indexes?**  
  Yes. The local version of DynamoDB is useful for developing and testing DynamoDB-backed applications. You can download the local version of DynamoDB here
* **Q: How does adding a global secondary index impact provisioned throughput and storage for a table?**  
  Similar to a DynamoDB table, a GSI consumes provisioned throughput when reads or writes are performed to it. A write that adds or updates a GSI item will consume write capacity units based on the size of the update. The capacity consumed by the GSI write is in addition to that needed for updating the item in the table. Note that if you add, delete, or update an item in a DynamoDB table, and if this does not result in a change to a GSI, then the GSI will not consume any write capacity units. This happens when an item without any GSI key attributes is added to the DynamoDB table, or an item is updated without changing any GSI key or projected attributes. A query to a GSI consumes read capacity units, based on the size of the items examined by the query. Storage costs for a GSI are based on the total number of bytes stored in that GSI. This includes the GSI key and projected attributes and values, and an overhead of 100 bytes for indexing purposes. Q: Can DynamoDB throttle my application writes to a table because of a GSI’s provisioned throughput? Because some or all writes to a DynamoDB table result in writes to related GSIs, it is possible that a GSI’s provisioned throughput can be exhausted. In such a scenario, subsequent writes to the table will be throttled. This can occur even if the table has available write capacity units. Q: How often can I change provisioned throughput at the index level?
* **Q: Can DynamoDB throttle my application writes to a table because of a GSI’s provisioned throughput?**  
  Because some or all writes to a DynamoDB table result in writes to related GSIs, it is possible that a GSI’s provisioned throughput can be exhausted. In such a scenario, subsequent writes to the table will be throttled. This can occur even if the table has available write capacity units.
* **Q: How does adding a global secondary index impact provisioned throughput and storage for a table?**  
   Similar to a DynamoDB table, a GSI consumes provisioned throughput when reads or writes are performed to it. A write that adds or updates a GSI item will consume write capacity units based on the size of the update. The capacity consumed by the GSI write is in addition to that needed for updating the item in the table. Note that if you add, delete, or update an item in a DynamoDB table, and if this does not result in a change to a GSI, then the GSI will not consume any write capacity units. This happens when an item without any GSI key attributes is added to the DynamoDB table, or an item is updated without changing any GSI key or projected attributes. A query to a GSI consumes read capacity units, based on the size of the items examined by the query. Storage costs for a GSI are based on the total number of bytes stored in that GSI. This includes the GSI key and projected attributes and values, and an overhead of 100 bytes for indexing purposes.
* **Q: How do I query local secondary indexes?**  
  Local secondary indexes can only be queried via the Query API. To query a local secondary index, explicitly reference the index in addition to the name of the table you’d like to query. You must specify the index partition attribute name and value. You can optionally specify a condition against the index key sort attribute. Your query can retrieve non-projected attributes stored in the primary index by performing a table fetch operation, with a cost of additional read capacity units. Both strongly consistent and eventually consistent reads are supported for query using local secondary index.
* **Q: Are there limits on the size of an item collection?**  
  Every item collection in Amazon DynamoDB is subject to a maximum size limit of 10 gigabytes. For any distinct partition key value, the sum of the item sizes in the table plus the sum of the item sizes across all of that table's local secondary indexes must not exceed 10 GB. The 10 GB limit for item collections does not apply to tables without local secondary indexes; only tables that have one or more local secondary indexes are affected. Although individual item collections are limited in size, the storage size of an overall table with local secondary indexes is not limited. The total size of an indexed table in Amazon DynamoDB is effectively unlimited, provided the total storage size (table and indexes) for any one partition key value does not exceed the 10 GB threshold.
* **Q: How much does DynamoDB FGAC cost?**  
  There is no additional charge for using FGAC. As always, you only pay for the provisioned throughput and storage associated with the DynamoDB table. Q: How do I get started? Refer to the Fine-Grained Access Control section of the DynamoDB Developer Guide to learn how to create an access policy, create an IAM role for your app (e.g. a role named AcmeFacebookUsers for a Facebook app_id of 34567), and assign your access policy to the role. The trust policy of the role determines which identity providers are accepted (e.g. Login with Amazon, Facebook, or Google), and the access policy describes which AWS resources can be accessed (e.g. a DynamoDB table). Using the role, your app can now to obtain temporary credentials for DynamoDB by calling the AssumeRoleWithIdentityRequest API of the AWS Security Token Service (STS).
* **Q: Can I grant access based on a canonical user id instead of separate ids for the user based on the identity provider they logged in with?**  
  Not without running a “token vending machine”. If a user retrieves federated access to your IAM role directly using Facebook credentials with STS, those temporary credentials only have information about that user’s Facebook login, and not their Amazon login, or Google login. If you want to internally store a mapping of each of these logins to your own stable identifier, you can run a service that the user contacts to log in, and then call STS and provide them with credentials scoped to whatever partition key value you come up with as their canonical user
* **Q: Do your prices include taxes?**  
  For details on taxes, see Amazon Web Services Tax Help
* **Q: What is the maximum throughput I can provision for a single DynamoDB table?**  
  DynamoDB is designed to scale without limits However, if you wish to exceed throughput rates of 10,000 write capacity units or 10,000 read capacity units for an individual table, you must first contact Amazon through this online form. If you wish to provision more than 20,000 write capacity units or 20,000 read capacity units from a single subscriber account you must first contact us using the form described above.
* **Q: How do I know if I am exceeding my provisioned throughput capacity?**  
  DynamoDB publishes your consumed throughput capacity as a CloudWatch metric. You can set an alarm on this metric so that you will be notified if you get close to your provisioned capacity.
* **Q. How can I set up single master cross-region replication for a table?**  
  You can create cross-region replicas using the DynamoDB Cross-region Replication library.
* **Q: Does DynamoDB Streams display all updates made to my DynamoDB table in order?**  
  Changes made to any individual item will appear in the correct order. Changes made to different items may appear in DynamoDB Streams in a different order than they were received.
* **Q: Can I use my Kinesis Client Library to access DynamoDB Streams?**  
  Yes, developers who are familiar with Kinesis APIs will be able to consume DynamoDB Streams easily. You can use the DynamoDB Streams Adapter, which implements the Amazon Kinesis interface, to allow your application to use the Amazon Kinesis Client Libraries (KCL) to access DynamoDB Streams. For more information about using the KCL to access DynamoDB Streams, please see our documentation
* **Q: What is the Amazon DynamoDB Logstash Plugin for Elasticsearch?**  
  Elasticsearch is a popular open source search and analytics engine designed to simplify real-time search and big data analytics. Logstash is an open source data pipeline that works together with Elasticsearch to help you process logs and other event data. The Amazon DynamoDB Logstash Plugin make is easy to integrate DynamoDB tables with Elasticsearch clusters.
* **Q: Is the DynamoDB Storage Backend for Titan a fully managed service?**  
  No. The DynamoDB storage backend for Titan manages the storage layer for your Titan workload. However, the plugin does not do provisioning and managing of the client side. For simple provisioning of Titan we have developed a CloudFormation template that sets up DynamoDB Storage Backend for Titan with Gremlin Server; see the instructions available here
* **Q: How can I use tags for cost allocation?**  
  You can use cost allocation tags to categorize and track your AWS costs. AWS Cost Explorer and detailed billing reports support the ability to break down AWS costs by tag. Typically, customers use business tags such as cost center/business unit, customer, or project to associate AWS costs with traditional cost-allocation dimensions. However, a cost allocation report can include any tag. This enables you to easily associate costs with technical or security dimensions, such as specific applications, environments, or compliance programs.
* **Q: How many tags can I add to single DynamoDB table?**  
  You can add up to 50 tags to a single DynamoDB table. Tags with the prefix “aws:” cannot be manually created and do not count against your tags per resource limit.
* **Q. Can I encrypt DynamoDB Streams?**  
  Currently, you cannot enable encryption at rest for DynamoDB Streams. If encryption at rest is a compliance/regulatory requirement, we recommend turning off DynamoDB Streams for encrypted tables.
* For more information, see How Envelope Encryption Works with Supported AWS Service
* **Q. Can I use different service default keys for different tables?**  
  No, DynamoDB uses a single service default key for encrypting all of your DynamoDB tables.

## FAQs IAM
<p align="right"><a href="#top">Top</a></p>

* **Q: Can IAM users have individual EC2 SSH keys?**  
  Not in the initial release. IAM does not affect EC2 SSH keys or Windows RDP certificates. This means that although each user has separate credentials for accessing web service APIs, they must share SSH keys that are common across the AWS account under which users have been defined.
* **Q: Where can I use my SSH keys?**  
  Currently, IAM users can use their SSH keys only with AWS CodeCommit to access their repositories.
* **Q: How do I assume an IAM role?**  
  You assume an IAM role by calling the AWS Security Token Service (STS) AssumeRole APIs (in other words, AssumeRole, AssumeRoleWithWebIdentity, and AssumeRoleWithSAML). These APIs return a set of temporary security credentials that applications can then use to sign requests to AWS service APIs.
* **Q: How can I easily remove unnecessary permissions?**  
  To help you determine which permissions are needed, the IAM console now displays service last accessed data that shows the hour when an IAM entity (a user, group, or role) last accessed an AWS service. Knowing if and when an IAM entity last exercised a permission can help you remove unnecessary permissions and tighten your IAM policies with less effort.
* You can also use the policy simulator to understand how IAM policies and resource-based policies work together to grant or deny access to AWS resources.
* **Q: How can I request temporary security credentials for federated users?**  
  You can call the GetFederationToken, AssumeRole, AssumeRoleWithSAML, or AssumeRoleWithWebIdentity STS APIs.
* **Q: Can a temporary security credential be revoked prior to its expiration?**  
  No. When requesting temporary credentials, we recommend the following: When creating temporary security credentials, set the expiration to a value that is appropriate for your application. Because root account permissions cannot be restricted, use an IAM user and not the root account for creating temporary security credentials. You can revoke permissions of the IAM user that issued the original call to request it. This action almost immediately revokes privileges for all temporary security credentials issued by that IAM user
* **Q: Can federated users access AWS APIs?**  
  Yes. You can programmatically request temporary security credentials for your federated users to provide them secure and direct access to AWS APIs. We have provided a sample application that demonstrates how you can enable identity federation, providing users maintained by Microsoft Active Directory access to AWS service APIs. For more information, see Using Temporary Security Credentials to Request Access to AWS Resources.
* **Q: Can federated users access the AWS Management Console?**  
  Yes. There are a couple ways to achieve this. One way is by programmatically requesting temporary security credentials (such as GetFederationToken or AssumeRole) for your federated users and including those credentials as part of the sign-in request to the AWS Management Console. After you have authenticated a user and granted them temporary security credentials, you generate a sign-in token that is used by the AWS single sign-on (SSO) endpoint. The user’s actions in the console are limited to the access control policy associated with the temporary security credentials. For more details, see Creating a URL that Enables Federated Users to Access the AWS Management Console (Custom Federation Broker). Alternatively, you can post a SAML assertion directly to AWS sign-in (https://signin.aws.amazon.com/saml). The user’s actions in the console are limited to the access control policy associated with the IAM role that is assumed using the SAML assertion. For more details, see Enabling SAML 2.0 Federated Users to Access the AWS Management Console. Using either approach allows a federated user to access the console without having to sign in with a user name and password. We have provided a sample application that demonstrates how you can enable identity federation, providing users maintained by Microsoft Active Directory access to the AWS Management Console.
* **Q: What is web identity federation?**  
  Web identity federation allows you to create AWS-powered mobile apps that use public identity providers (such as Amazon Cognito, Login with Amazon, Facebook, Google, or any OpenID Connect-compatible provider) for authentication. With web identity federation, you have an easy way to integrate sign-in from public identity providers (IdPs) into your apps without having to write any server-side code and without distributing long-term AWS security credentials with the app. For more information about web identity federation and to get started, see About Web Identity Federation.
* **Q: Are there any default quota limits associated with IAM?**  
  Yes, by default your AWS account has initial quotas set for all IAM-related entities. For details see Limitations on IAM Entities and Objects. These quotas are subject to change. If you require an increase, you can access the Service Limit Increase form via the Contact Us page, and choose IAM Groups and Users from the Limit Type drop-down list.
* if you want to use a physical authentication device then you will need to purchase an authentication device that is compatible with AWS MFA from Gemalto, a third party provider. For more details, please visit Gemalto’s website.
* If your MFA device is lost, damaged, stolen, or not working, you can sign in using alternative factors of authentication, deactivate the MFA device, and activate a new device. As a security best practice, we recommend that you change your root account's password.
* **Q. Which services does MFA-protected API access work with?**  
  MFA-protected API access is supported by all AWS services that support temporary security credentials. For a list of supported services, see AWS Services that Work with IAM and review the column labeled Supports temporary security credentials.
* **Q. Does MFA-protected API access control API access for AWS root accounts?**  
  No, MFA-protected API access only controls access for IAM users. Root accounts are not bound by IAM policies, which is why we recommend that you create IAM users to interact with AWS service APIs rather than
* **Q. Does MFA-protected API access control API access for AWS root accounts?**  
  No, MFA-protected API access only controls access for IAM users. Root accounts are not bound by IAM policies, which is why we recommend that you create IAM users to interact with AWS service APIs rather than use AWS root account credentials.
* **Q. How does MFA-protected API access interact with existing MFA use cases such as S3 MFA Delete?**  
  MFA-protected API access and S3 MFA Delete do not interact with each other. S3 MFA Delete currently does not support temporary security credentials. Instead, calls to the S3 MFA Delete API must be made using long-term access keys.
* **Q. Does MFA-protected API access work for federated users?**  
  Customers cannot use MFA-protected API access to control access for federated users. The GetFederatedSession API does not accept MFA parameters. Since federated users can’t authenticate with AWS MFA devices, they are unable to access resources designated using MFA-protected API access.

## FAQs API GW
<p align="right"><a href="#top">Top</a></p>

* **Q: What is an usage plan?**  
  Usage plans help you declare plans for third-party developers that restrict access only to certain APIs, define throttling and request quota limits, and associate them with API keys. You can also extract utilization data on an per-API key basis to analyze API usage and generate billing documents. For example, you can create a basic, professional, and enterprise plans – you can configure the basic usage plan to only allow 1,000 requests per day and a maximum of 5 requests per second (RPS).
* **Q: What if I mistakenly deployed to a stage?**  
  Amazon API Gateway saves the history of your deployments. At any point, using the Amazon API Gateway APIs or the console, you can roll back a stage to a previous deployment.
* **Q: How do I monetize my APIs on API Gateway?**  
  You can monetize your APIs on API Gateway by publishing them as products in AWS Marketplace. You will first need to register as a seller in AWS Marketplace, and submit your usage plans on API Gateway as products. Read here to learn more about API Monetization.
* **Q: How does AWS Signature Version 4 work?**  
  You can use AWS credentials -- access and secret keys – to sign requests to your service and authorize access like other AWS services. The signing of an Amazon API Gateway API request is managed by the custom API Gateway SDK generated for your service. You can retrieve temporary credentials associated with a role in your AWS account using Amazon Cognito.
* **Q: What is a custom authorizer?**  
  Custom authorizers are AWS Lambda functions. With custom request authorizers, you will be able to authorize access to APIs using a bearer token auth strategy such as OAuth. When an API is called, API Gateway checks if a custom authorizer is configured, API Gateway then calls the Lambda function with the incoming authorization token. You can use Lambda to implement various authorization strategies (e.g. JWT verification, OAuth provider callout) that return IAM policies which are used to authorize the request. If the policy returned by the authorizer is valid, API Gateway will cache the policy associated with the incoming token for up to 1 hour.
* **Q: How are throttling rules applied?**  
  First. API Gateway checks against your AWS account limit. If the traffic is below the set account limit, API Gateway checks the limit you have set on a stage or method. If the traffic is below the stage limit, then API Gateway applies the usage plans limits you set on a per-API key basis.
* **Q: How am I charged for using Amazon API Gateway?**  
  Amazon API Gateway rates are $3.50 per million API calls, plus the cost of data transfer out, in gigabytes. If you choose to provision a cache for your API, hourly rates apply. Please see the API Gateway Pricing pages for details on data transfer and caching costs.

## FAQs SES
<p align="right"><a href="#top">Top</a></p>

* **Q: What should I do after I'm finished testing and evaluating Amazon SES?**  
  Once you are ready to use Amazon SES to send email, you can request an Amazon SES sending limit increase. If granted, this increase will move your account out of the sandbox environment so that you can begin sending email to your customers. You will no longer need to verify recipient email addresses or recipient domains, and you will be able to send much larger quantities of email. To request a sending limit increase, please complete the request form in Support Center. We generally respond to these requests within 24 hours.
* **Q: What is the Amazon SES sandbox?**  
  The Amazon SES sandbox is an area in which new users can test the capabilities of Amazon SES. New Amazon SES users are automatically placed in the sandbox. While in the sandbox, you will only be able to send mail to verified email addresses, or to email addresses associated with the Amazon SES mailbox simulator. Additionally, while in the sandbox, you can send no more than 200 messages per 24-hour period, and no more than one message per second. When you are ready to move out of the sandbox, you can submit an SES Sending Limit Increase request.
* **Q: Is there a limit on the size of emails Amazon SES will deliver?**  
  Amazon SES will accept email messages up to 10 MB in size. This includes any images and attachments that are part of the message.
* The total number of email addresses in the To:, CC:, and BCC: field must not exceed 50 recipients.
* Sending limits are based on recipients rather than on messages. You can check your sending limits at any time by using the Amazon SES console.
* For more information about the Amazon SES mailbox simulator, see Testing Amazon SES Email Sending in the Amazon SES Developer Guide.
* **Q. Where does Amazon SES send my bounce, complaint, and delivery notifications?**  
  Delivery notifications are available through Amazon SNS. Bounces and complaints can be sent to you by email, through Amazon SNS, or both. If you choose to receive bounce and complaint notifications by email, Amazon SES will send you your bounce and complaint notifications based on the following logic: If you used the SMTP interface to send the message, then notifications go to the address specified in SMTP's required MAIL FROM command, which overrides any Return-Path header specified in the SMTP DATA. If you used the SendEmail API operation to send the message, then: If you specified SendEmail's optional ReturnPath parameter, then notifications go to the specified address. Otherwise, notifications go to the address specified in SendEmail's required Source parameter, which populates the From: header of the message. If you used the SendRawEmail API operation to send the message, then: If you specified SendRawEmail's optional Source parameter, then notifications go to that address, overriding any Return-Path header specified in the raw message. Otherwise, if the Return-Path header was specified in the raw message, then notifications go to that address. Otherwise, notifications go to the address in the From: header of the raw message.
* **Q: How can I monitor the bounce and complaint rates for the email I send using Amazon SES?**  
  Amazon SES provides three main ways to monitor your bounces, complaints, deliveries, sent emails, and rejected emails. The first method is to use the Amazon SES console, Amazon SES API, or Amazon CloudWatch to access basic email sending metrics across your entire AWS account. The second method is to set up Amazon SES to send you detailed feedback notifications through email or through Amazon SNS. The third method is to use Amazon SES event publishing. With event publishing, you categorize your emails and collect event data for each category of emails separately using either Amazon CloudWatch or Amazon Kinesis Firehose. You can set up Amazon Kinesis Firehose to send the event records to Amazon Redshift, Amazon S3, or Amazon Elasticsearch Service. If you use Amazon Elasticsearch Service, you can visualize your event data using Kibana. For more information about monitoring methods, see Monitoring Your Amazon SES Sending Activity in the Amazon SES Developer Guide.
* **Q: How is Amazon SES different from Amazon SNS?**  
  Amazon SES is for applications that need to send communications via email. Amazon SES supports custom email header fields, and many MIME types. By contrast, Amazon Simple Notification Service (Amazon SNS) is for messaging-oriented applications, with multiple subscribers requesting and receiving "push" notifications of time-critical messages via a choice of transport protocols, including HTTP, Amazon SQS, and email. The body of an Amazon SNS notification is limited to 8192 characters of UTF-8 strings, and is not intended to support multimedia content.
* **Q: How do I make requests to Amazon SES?**  
  Amazon SES accepts Query requests over HTTPS. These requests use verbs such as GET or POST, and a parameter named Action to indicate the action being performed. For security reasons, Amazon SES does not support HTTP requests; you must use HTTPS instead.

## FAQs Cloud Formation
<p align="right"><a href="#top">Top</a></p>

* **Q: Can I install software at stack creation time using AWS CloudFormation?**  
  Yes. AWS CloudFormation provides a set of application bootstrapping scripts that enable you to install packages, files, and services on your EC2 instances by simply describing them in your CloudFormation template. For more details and a how-to see Bootstrapping Applications via AWS CloudFormation.
* **Q: Can I use AWS CloudFormation with Chef?**  
  Yes. AWS CloudFormation can be used to bootstrap both the Chef Server and Chef Client software on your EC2 instances. For more details and a how-to see Integrating AWS CloudFormation with Chef.
* **Q: Can I use AWS CloudFormation with Puppet?**  
  Yes. AWS CloudFormation can be used to bootstrap both the Puppet Master and Puppet Client software on your EC2 instances. For more details and a how-to see Integrating AWS CloudFormation with Puppet
* **Q: Can stack creation wait for my application to start up?**  
  Yes. AWS CloudFormation provides a WaitCondition resource that acts as a barrier, blocking the creation of other resources until a completion signal is received from an external source such as your application, or management system.
* **Q: Are there limits to the size of description fields?**  
  Template, Parameter, Output, and Resource description fields are limited to 4096 characters.
* **Q: Are there limits to the number of parameters or outputs in a template?**  
  You can include up to 60 parameters and 60 outputs in a template.

## FAQs Kinesis
<p align="right"><a href="#top">Top</a></p>

* **Q: How do I decide the throughput of my Amazon Kinesis data stream?**
  The throughput of an Amazon Kinesis data stream is determined by the number of shards within the data stream. Follow the steps below to estimate the initial number of shards your data stream needs. Note that you can dynamically adjust the number of shards within your data stream via resharding. Estimate the average size of the record written to the data stream in kilobytes (KB), rounded up to the nearest 1 KB. (average_data_size_in_KB) Estimate the number of records written to the data stream per second. (number_of_records_per_second) Decide the number of Amazon Kinesis Applications consuming data concurrently and independently from the data stream. (number_of_consumers) Calculate the incoming write bandwidth in KB (incoming_write_bandwidth_in_KB), which is equal to the average_data_size_in_KB multiplied by the number_of_records_per_seconds. Calculate the outgoing read bandwidth in KB (outgoing_read_bandwidth_in_KB), which is equal to the incoming_write_bandwidth_in_KB multiplied by the number_of_consumers. You can then calculate the initial number of shards (number_of_shards) your data stream needs using the following formula: number_of_shards = max (incoming_write_bandwidth_in_KB/1000, outgoing_read_bandwidth_in_KB/2000) Q: What is the minimum throughput I can request for my Amazon Kinesis data stream? The throughput of an Amazon Kinesis data stream scales by unit of shard. One single shard is the smallest throughput of a data stream, which provides 1MB/sec data input and 2MB/sec data output.
* **Q: What programming language is Amazon Kinesis Producer Library (KPL) available in?**
  Amazon Kinesis Producer Library (KPL)'s core is built with C++ module and can be compiled to work on any platform with a recent C++ compiler. The library is currently available in a Java interface. We are looking to add support for other programming languages.
* **Q: What is Amazon Kinesis Agent?**
  Amazon Kinesis Agent is a pre-built Java application that offers an easy way to collect and send data to your Amazon Kinesis data stream. You can install the agent on Linux-based server environments such as web servers, log servers, and database servers. The agent monitors certain files and continuously sends data to your data stream. For more information, see Writing with Agents
* **Q: What is Amazon Kinesis Connector Library?**
  Amazon Kinesis Connector Library is a pre-built library that helps you easily integrate Amazon Kinesis Data Streams with other AWS services and third-party tools. Amazon Kinesis Client Library (KCL) for Java | Python | Ruby | Node.js | .NET is required for using Amazon Kinesis Connector Library. The current version of this library provides connectors to Amazon DynamoDB, Amazon Redshift, Amazon S3, and Elasticsearch. The library also includes sample connectors of each type, plus Apache Ant build files for running the samples.
* **Q: Does Amazon Kinesis Data Streams remain available when I change the throughput of my Amazon Kinesis data stream using UpdateShardCount or via resharding?**
  Yes. You can continue adding data to and reading data from your Amazon Kinesis data stream while you use UpdateShardCount or reshard to change the throughput of the data stream.
* **Q: When I use Kinesis Data Streams, how secure is my data?**
  Kinesis is secure by default. Only the account and data stream owners have access to the Kinesis resources they create. Kinesis supports user authentication to control access to data. You can use AWS IAM policies to selectively grant permissions to users and groups of users. You can securely put and get your data from Kinesis through SSL endpoints using the HTTPS protocol. If you need extra security you can use server-side encryption with AWS KMS master keys to encrypt data stored in your data stream. AWS KMS allows you to use AWS generated KMS master keys for encryption, or if you prefer you can bring your own master key into AWS KMS. Lastly, you can use your own encryption libraries to encrypt data on the client-side before putting the data into Kinesis.
* **Q: Can I privately access Kinesis Data Streams APIs from my Amazon Virtual Private Cloud (VPC) without using public IPs?**
  Yes, you can privately access Kinesis Data Streams APIs from your Amazon Virtual Private Cloud (VPC) by creating VPC Endpoints. With VPC Endpoints, the routing between the VPC and Kinesis Data Streams is handled by the AWS network without the need for an Internet gateway, NAT gateway, or VPN connection. The latest generation of VPC Endpoints used by Kinesis Data Streams are powered by AWS PrivateLink, a technology that enables private connectivity between AWS services using Elastic Network Interfaces (ENI) with private IPs in your VPCs. To learn more about PrivateLink, visit the PrivateLink documentation
* **Q: What does server-side encryption for Kinesis Data Streams encrypt?**
  Server-side encryption encrypts the payload of the message along with the partition key, which is specified by the data stream producer applications.
* **Q: Can you walk me through the encryption lifecycle of my data from the point in time when I send it to a Kinesis data stream with server-side encryption enabled, and when I retrieve it?**
  The following walks you through how Kinesis Data Streams uses AWS KMS CMKs to encrypt a message before it is stored in the PUT path, and to decrypt it after it is retrieved in the GET path. Kinesis and AWS KMS perform the following actions (including decryption) when you call putRecord(s) or getRecords on a data stream with server-side encryption enabled. Data is sent from a customer’s Kinesis producer application (client) to Kinesis using SSL via HTTPS. Data is received by Kinesis, stored in RAM, and encryption is applied to the payload and partition key of a record. Kinesis requests a plaintext input keying material (IKM) and a copy of the IKM is encrypted by using the customer’s selected KMS master key. AWS KMS creates an IKM, encrypts it by using the master key, and sends both the plaintext IKM and the encrypted IKM to Kinesis. Kinesis uses the plaintext IKM to derive data keys that are unique per-record. Kinesis encrypts the payload and partition key using the data keys and removes the plaintext key from memory. Kinesis appends the encrypted IKM to the encrypted data. The plaintext IKM is cached in memory for reuse until it expires after 5 minutes. Kinesis delivers the encrypted message to a backend store where it is stored at rest and fetch-able by a getRecords call. Kinesis and AWS KMS perform the following actions (including decryption) when you call getRecords. When a getRecords call is made, the frontend of Kinesis retrieves the encrypted record from the backend service. Kinesis makes a request to KMS using a token generated by the customer’s request. AWS KMS authorizes it. Kinesis decrypts the encrypted IKM stored with the record. Kinesis recreates the per-record data keys from the decrypted IKM. If authorized, Kinesis decrypts the payload and removes the plaintext data key from memory. Kinesis delivers the payload over SSL and HTTPS to the Kinesis consumer (client) requesting the records.
* **Q: Is Amazon Kinesis Data Streams available in AWS Free Tier?**
  No. Amazon Kinesis Data Streams is not currently available in AWS Free Tier. AWS Free Tier is a program that offers free trial for a group of AWS services. For more details about AWS Free Tier, see AWS Free Tier.

### FAQs Trusted Advisor
<p align="right"><a href="#top">Top</a></p>

* **Q. How can I get the Service Limit data with command-line tools?**
  You can retrieve Service Limit data using the AWS CLI. This AWS Command Line Interface command displays the regions Trusted Advisor has flagged as approaching or reaching the limit for Amazon EC2 on-demand instance utilization, sorted by region name. aws support describe-trusted-advisor-check-result --language en --check-id eW7HH0l7J9 --query 'result.sort_by(flaggedResources[?status!=`ok`],&metadata[2])[].metadata' --output table You can check any of the limits covered by Trusted Advisor using this method. For more details, see Check Categories, IDs, and Report Columns
* **Q. I just purchased a new Reserved Instance. Why isn’t it showing up in the recommendation?**
  New Reserved Instance purchases are updated on a daily basis. Refresh the check 24 hours after you make your purchase to see the new recommendation. Also note that the check does not include third-party Reserved Instances purchased from the Reserved Instance Marketplace
* **Q. I have many accounts, and the Availability Zones are different for each one. How do you account for that?**
  We normalize all Availability Zones across all Consolidated Billing accounts and reflect the values using the primary payer account mapping.
* **Q. Why are there separate sections for 1 year and 3 year Reserved Instances?**
  Customers have a choice between buying 1 year and 3 year term Reserved Instances from AWS. This check assumes you will purchase Reserved Instances for either 1 year or 3 year terms, not both. As a result, recommendations for purchasing additional 1 year or 3 year term Reserved Instances are not additive across both term lengths, so recommendations are called out separately. To illustrate: In a recommendation for three additional 1 year Reserved Instances or four additional 3 year Reserved Instances, we are recommending the purchase of three or four Reserved Instances respectively, not a total of seven additional Reserved Instances.
* **Q. Are all instance types included in the recommendation?**
  Recommendations are available for Amazon Linux/UNIX and Windows Reserved Instances. The calculation excludes usage and recommendations for Red Hat Enterprise Linux, SUSE Linux Enterprise, Amazon RDS, Amazon ElastiCache, and others.

### FAQs SQS
<p align="right"><a href="#top">Top</a></p>

* Amazon SQS provides common middleware constructs such as dead-letter queues and poison-pill management.
* **Q: How does Amazon SQS handle unsuccessfully-processed messages?**
  In Amazon SQS, you can use the API or the console to configure dead letter queues, which are queues that receive messages from other source queues. If you make a queue into a dead letter queue, it receives messages after a maximum number of processing attempts cannot be completed. You can use dead letter queues to isolate messages that can't be processed for later analysis. For more information, see "Can I use a dead letter queue with FIFO queues?" on this page and Using Amazon SQS Dead Letter Queues in the Amazon SQS Developer Guide.
* **Q: How does Amazon SQS allow multiple readers to access the same message queue without losing messages or processing them multiple times?**
  Every Amazon SQS queue has a configurable visibility timeout. A message is not visible to any other reader for a designated amount of time when it is read from a message queue. As long as the amount of time it takes to process the message is less than the visibility timeout, every message is processed and deleted. If the component processing of the message fails or becomes unavailable, the message again becomes visible to any component reading the message queue once the visibility timeout ends. This allows multiple components to read messages from the same message queue, each one working to process different messages. Q: What is the maximum limit for message visibility? The maximum visibility timeout for an Amazon SQS message is 12 hours.
* **Q: Does Amazon SQS support message metadata?**
  Yes. An Amazon SQS message can contain up to 10 metadata attributes. You can use message attributes to separate the body of a message from the metadata that describes it. This helps process and store information with greater speed and efficiency because your applications don't have to inspect an entire message before understanding how to process it. Amazon SQS message attributes take the form of name-type-value triples. The supported types include string, binary, and number (including integer, floating-point, and double). For more information, see Using Amazon SQS Message Attributes in the Amazon SQS Developer Guide.
* **Q: How can I determine the time-in-queue value?**
  To determine the time-in-queue value, you can request the SentTimestamp attribute when receiving a message. Subtracting that value from the current time results in the time-in-queue value.
* **Q: When should I use Amazon SQS long polling, and when should I use Amazon SQS short polling?**
  In almost all cases, Amazon SQS long polling is preferable to short polling. Long-polling requests let your queue consumers receive messages as soon as they arrive in your queue while reducing the number of empty ReceiveMessageResponse instances returned. Amazon SQS long polling results in higher performance at reduced cost in the majority of use cases. However, if your application expects an immediate response from a ReceiveMessage call, you might not be able to take advantage of long polling without some modifications to your application. For example, if your application uses a single thread to poll multiple queues, switching from short polling to long polling will probably not work, because the single thread will wait for the long-poll timeout on any empty queues, delaying the processing of any queues that might contain messages. In
* **Q: When should I use Amazon SQS long polling, and when should I use Amazon SQS short polling?**
  In almost all cases, Amazon SQS long polling is preferable to short polling. Long-polling requests let your queue consumers receive messages as soon as they arrive in your queue while reducing the number of empty ReceiveMessageResponse instances returned. Amazon SQS long polling results in higher performance at reduced cost in the majority of use cases. However, if your application expects an immediate response from a ReceiveMessage call, you might not be able to take advantage of long polling without some modifications to your application. For example, if your application uses a single thread to poll multiple queues, switching from short polling to long polling will probably not work, because the single thread will wait for the long-poll timeout on any empty queues, delaying the processing of any queues that might contain messages. In such an application, it is a good practice to use a single thread to process only one queue, allowing the application to take advantage of the benefits that Amazon SQS long polling provides.
* For information about compatibility of other services with FIFO queues, see your service documentation.
* **Q: Which AWS CloudWatch metrics do Amazon SQS FIFO queues support?**
  FIFO queues support all metrics that standard queues support. For FIFO queues, all approximate metrics return accurate counts.
* **Q: Do Amazon SQS FIFO queues support multiple consumers?**
  By design, Amazon SQS FIFO queues don't serve messages from the same message group to more than one consumer at a time. However, if your FIFO queue has multiple message groups, you can take advantage of parallel consumers, allowing Amazon SQS to serve messages from different message groups to different consumers.
* **Q: What is the throughput limit for an Amazon SQS FIFO queue?**
  Without batching, FIFO queues can support up to 300 messages per second (300 SendMessage, ReceiveMessage, or DeleteMessage operations per second). If you take advantage of the maximum batching of 10 messages per operation, FIFO queues can support up to 3,000 messages per second. Amazon SQS standard queues have unlimited throughput.
* **Q: Are there any limits specific to FIFO queue attributes?**
  The name of a FIFO queue must end with the .fifo suffix. The suffix counts towards the 80-character queue name limit. To determine whether a queue is FIFO, you can check whether the queue name ends with the suffix.
* **Q: Why are there separate ReceiveMessage and DeleteMessage operations?**
  When Amazon SQS returns a message to you, the message stays in the message queue whether or not you actually receive the message. You're responsible for deleting the message and the deletion request acknowledges that you’re done processing the message. If you don’t delete the message, Amazon SQS will deliver it again on when it receives another receive request. For more information, see Visibility Timeout in the Amazon SQS Developer Guide.
* **Q: Are there any charges for using SSE with Amazon SQS?**
  There are no additional Amazon SQS charges. However, there are charges for calls from Amazon SQS to AWS KMS. For more information, see AWS Key Management Service Pricing. The charges for using AWS KMS depend on the data key reuse period configured for your queues.
* You can configure the Amazon SQS message retention period to a value from 1 minute to 14 days. The default is 4 days.
* **Q: Are there restrictions on the names of Amazon SQS message queues?**
  You can use alphanumeric characters, hyphens (-), and underscores (_).
* **Q: Does Amazon SQS support anonymous access?**
  Yes. You can configure an access policy that allows anonymous users to access a message queue.
* **Q: Can I share messages between queues in different regions?**
  No. Each Amazon SQS message queue is independent within each region.
* **Q: What is the pricing structure between various regions?**
  You can transfer data between Amazon SQS and Amazon EC2 or AWS Lambda free of charge within a single region. When you transfer data between Amazon SQS and Amazon EC2 or AWS Lambda in different regions, you will be charged the normal data transfer rate.

### FAQs SNS
<p align="right"><a href="#top">Top</a></p>

* A common pattern is to use SNS to publish messages to Amazon SQS queues to reliably send messages to one or many system components asynchronously.
* If you're using messaging with existing applications, and want to move your messaging to the cloud quickly and easily, we recommend you consider Amazon MQ
* SNS currently supports CloudTrail auditing for authenticated calls only. CloudTrail Audit logs for unauthenticated ConfirmSubscription and Unsubscribe calls are not available at this time. For more information, see the CloudTrail section of the SNS Developer Guide
* **Q: How much does Amazon SNS cost?**
  With Amazon SNS, there is no minimum fee and you pay only for what you use. Users pay $0.50 per 1 million Amazon SNS Requests, $0.06 per 100,000 notification deliveries over HTTP, and $2.00 per 100,000 notification deliveries over email. For SMS messaging, users can send 100 free notification deliveries, and for subsequent messages charges vary by destination country. Amazon SNS also includes a Free Tier, where users can get started with Amazon SNS for free. Each month, Amazon SNS customers incur no charges for the first 1 million Amazon SNS requests, no charges for the first 100,000 notifications over HTTP, no charges for the first 100 notifications over SMS, and no charges for the first 1,000 notifications over email.
* **Q: Why are there two different APIs to list subscriptions?**
  The two APIs to list subscriptions perform different functions and return different results: The ListSubscriptionsByTopic API allows a topic owner to see the list of all subscribers actively registered to a topic. The ListSubscriptions API allows a user to get a list of all their active subscriptions (to one or more topics).
* **Q: Why are there two different APIs to list subscriptions?**
  The two APIs to list subscriptions perform different functions and return different results: The ListSubscriptionsByTopic API allows a topic owner to see the list of all subscribers actively registered to a topic. The ListSubscriptions API allows a user to get a list of all their active subscriptions (to one or more topics).
* **Q: Can subscribers selectively receive only a subset of messages published to a topic?**
  Yes, you can use message filtering on Amazon Simple Notification Service (SNS) to build simpler and more streamlined pub/sub architectures. Message filtering enables Amazon SNS topic subscribers to selectively receive only a subset of the messages they are interested in, as opposed to receiving all messages published to a topic. For more details, try our 10-minute tutorial, Filter Messages Published to Topics, or see the documentation.
* **Q: Are Amazon SQS FIFO queues compatible with Amazon Simple Notification Service (SNS)?**
   Amazon SNS does not currently support forwarding messages to Amazon SQS FIFO queues. You can use SNS to forward messages to standard queues.
* If the user owning the SQS queue is not the owner of the topic, Amazon SNS will require an explicit confirmation to the subscription request. Please refer to the Amazon SNS documentation for further details on subscribing an SQS queue to a topic and setting access control policies for SQS queues.
* **Q: What is the format of structured notification messages sent by Amazon SNS?**
  The notification message sent by Amazon SNS for deliveries over HTTP, HTTPS, Email-JSON and SQS transport protocols will consist of a simple JSON object, which will include the following information: MessageId: A Universally Unique Identifier, unique for each notification published. Timestamp: The time (in GMT) at which the notification was published. TopicArn: The topic to which this message was published Type: The type of the delivery message, set to “Notification” for notification deliveries. UnsubscribeURL: A link to unsubscribe the end-point from this topic, and prevent receiving any further notifications. Message: The payload (body) of the message, as received from the publisher. Subject: The Subject field – if one was included as an optional parameter to the publish API call along with the message. Signature: Base64-encoded “SHA1withRSA” signature of the Message, MessageId, Subject (if present), Type, Timestamp, and Topic values. SignatureVersion: Version of the Amazon SNS signature used. Notification messages sent over the “Email” transport only contain the payload (message body) as received from the publisher.
* **Q: Can multiple users publish to a single topic?**
  A topic owner can set explicit permissions to allow more than one user (with a valid AWS ID) to publish to a topic. By default, only topic owners have permissions to publish to a topic.
* **Q: How can users verify that notification messages are sent from Amazon SNS?**
  To ensure the authenticity of the notifications, Amazon SNS will sign all notification deliveries using a cryptographically secure, asymmetric mechanism (private-public key pair based on certificates). Amazon SNS will publish its certificate to a well-known location (e.g. http://sns.us-east-1.amazonaws.com/SimpleNotificationService.pem for the US East region) and sign messages with the private key of that certificate. Developers/applications can obtain the certificate and validate the signature in the notifications with the certificate’s public key, to ensure that the notification was indeed sent out by Amazon SNS. For further details on certificate locations, please refer to the Amazon SNS details page.
* **Q: Do publishers have to sign messages as well?**
  Amazon SNS requires publishers with AWS IDs to validate their messages by signing messages with their secret AWS key; the signature is then validated by Amazon SNS. Q: Can a publisher/subscriber use SSL to secure messages?
* **Q: Do publishers have to sign messages as well?**
  Amazon SNS requires publishers with AWS IDs to validate their messages by signing messages with their secret AWS key; the signature is then validated by Amazon SNS.
* **Q: Does Amazon SNS guarantee that messages are delivered to the subscribed endpoint?**
  When a message is published to a topic, Amazon SNS will attempt to deliver notifications to all subscribers registered for that topic. Due to potential Internet issues or Email delivery restrictions, sometimes the notification may not successfully reach an HTTP or Email end-point. In the case of HTTP, an SNS Delivery Policy can be used to control the retry pattern (linear, geometric, exponential backoff), maximum and minimum retry delays, and other parameters. If it is critical that all published messages be successfully processed, developers should have notifications delivered to an SQS queue (in addition to notifications over other transports).
* **Q: Do the AWS phone numbers change?**
  Yes. Amazon SNS uses a pool of long codes or short codes to send SMS notifications. So while there is a possibility that SMS notifications come from multiple numbers, Amazon SNS ensures that the messages sent from an AWS account to a specific phone number, always come from the same long code or short code. This is called "Sticky Sender ID".
* **Q: Is time-based or scheduled delivery supported for SMS messages?**
  No. Amazon SNS does not currently support time-based or scheduled delivery.
* **Q: How do I know if a recipient device has ‘opted out’ of Global SMS?**
  The SNS console displays the list of opted out numbers for your account. Additionally, the Amazon SNS API provides the ListPhoneNumbersOptedOut request for listing opted out phone numbers.
* **Q: Does SMS support delivery to VoIP services like Google Voice or Hangouts?**
  Yes. Amazon SNS does support delivery to VoIP services that can receive SMS messages.
* Each 64KB chunk of published data is billed as 1 request. For example, a single API call with a 256KB payload will be billed as four requests. The following Unicode characters are accepted: #x9 | #xA | #xD | [#x20 to #xD7FF] | [#xE000 to #xFFFD] | [#x10000 to #x10FFFF] according to http://www.w3.org/TR/REC-xml/#charsets
* **Q: Are there TCP ports that should be used for cross-region communication between SNS and EC2?**
  Yes, cross-region communication between SNS and EC2 on ports other than 80/443/4080/8443 is not guaranteed to work and should be avoided.
* **Q: Can one token subscribe to multiple topics?**
  Yes. Each token can be subscribed to an unlimited number of SNS topics.
* **Q: Does SNS support direct addressing for SMS or Email?**
  At this time, direct addressing is only supported for mobile push endpoints (APNS, GCM, ADM, WNS, MPNS, Baidu) and SMS. Email messaging requires the use of topics.
* **Q: What message attributes are supported in SNS?**
  SNS supports different message attributes for each endpoint type, depending on what the endpoint types each support themselves. For SQS endpoints, you can specify up to 10 name-type-value triples per message. Types supported include: String, Binary and Number (including integers, floating point, and doubles). For mobile push endpoints, you can take advantage of specific message attributes that each mobile platform supports (such as notification type).
* **Q: What is the default TTL?**
  SNS uses a default Time to Live (TTL) of 4 weeks for all mobile platforms.
* **Q: Are there any limits to the concurrency of AWS Lambda functions?**
  AWS Lambda currently supports 100 concurrent requests per AWS account. If your Amazon SNS message deliveries to AWS Lambda contribute to crossing these concurrency limits, your Amazon SNS message deliveries will be throttled. If AWS Lambda throttles an Amazon SNS message, Amazon SNS will retry the delivery attempts. For more information about AWS Lambda concurrency limits, please refer to AWS Lambda documentation.
* **Q: What are VoIP Push Notifications for iOS?**
  In iOS 8 and later, voice-over-IP (VoIP) apps can register for VoIP remote notifications such that iOS can launch or wake the app, as appropriate, when an incoming VoIP call arrives for the user. The procedure to register for VoIP notifications is similar to registering for regular push notifications on iOS. For more information, please refer to our documentation.

### FAQs OpsWorks
<p align="right"><a href="#top">Top</a></p>

* **Q: How is OpsWorks for Chef Automate different from OpsWorks Stacks?**
  OpsWorks for Chef Automate is a configuration management service that helps you instantly provision a Chef server and lets the service operate it, including performing backups and software upgrades. The service offers full compatibility with Chef’s Supermarket cookbooks and recipes. It supports native Chef tools such as TestKitchen and Knife. The OpsWorks Stacks service helps you model, provision, and manage your applications on AWS using the embedded Chef solo client that is installed on Amazon EC2 instances on your behalf. To learn more, see OpsWorks Stacks.
* **Q: What is Chef Automate?**
  Chef Automate gives you a full-stack, continuous deployment pipeline, automated testing for compliance and security, and visibility into everything that's happening along the way. It builds on Chef for infrastructure automation, InSpec for compliance automation, and Habitat for application automation. You can transform your company into a highly collaborative, software-driven organization with Chef Automate as the engine. To learn more, see the Chef Automate product details page.
* **Q: I am an AWS OpsWorks Stacks customer. Should I migrate to the new OpsWorks for Chef Automate service?**
  OpsWorks Stacks customers who are looking for full Chef server compatibility are encouraged to use OpsWorks for Chef Automate. To learn more about OpsWorks Stacks, see the OpsWorks Stacks product details page.
* **Q: How can I restore my Chef server to an earlier point in time?**
  After browsing through your available backups, you can choose a point in time from which to restore your Chef server. Server backups contain only Chef software persistent data such as cookbooks and registered nodes.
* **Q: How do I upgrade my Chef nodes to a newer release version?**
  Chef node upgrades can be done at your convenience by using the Chef omnibus recipe. Although OpsWorks regularly performs Chef server version upgrades on your behalf, your Chef nodes continue to operate even if they remain on the earlier version.

### FAQs Route 53
<p align="right"><a href="#top">Top</a></p>

* **Q. Does Amazon Route 53 offer a Service Level Agreement (SLA)?**
  Yes. The Amazon Route 53 SLA provides for a service credit if a customer’s monthly uptime percentage is below our service commitment in any billing cycle. More information can be found here
* **Q. Does Amazon Route 53 provide query logging capability?**
  You can configure Amazon Route 53 to log information about the queries that Amazon Route 53 receives including date-time stamp, domain name, query type, location etc. When you configure query logging, Amazon Route 53 starts to send logs to CloudWatch Logs. You use CloudWatch Logs tools to access the query logs; For more information please see our documentation
* **Q. Is there a limit to the number of hosted zones I can manage using Amazon Route 53?**
  Each Amazon Route 53 account is limited to a maximum of 500 hosted zones and 10,000 resource record sets per hosted zone. Complete our request for a higher limit and we will respond to your request within two business days.
* **Q. Can I create multiple hosted zones for the same domain name?**
  Yes. Creating multiple hosted zones allows you to verify your DNS setting in a “test” environment, and then replicate those settings on a “production” hosted zone. For example, hosted zone Z1234 might be your test version of example.com, hosted on name servers ns-1, ns-2, ns-3, and ns-4. Similarly, hosted zone Z5678 might be your production version of example.com, hosted on ns-5, ns-6, ns-7, and ns-8. Since each hosted zone has a virtual set of name servers associated with that zone, Route 53 will answer DNS queries for example.com differently depending on which name server you send the DNS query to.
* **Q. Which DNS record types does Amazon Route 53 support?**
  Amazon Route 53 currently supports the following DNS record types: A (address record) AAAA (IPv6 address record) CNAME (canonical name record) CAA (certification authority authorization) MX (mail exchange record) NAPTR (name authority pointer record) NS (name server record) PTR (pointer record) SOA (start of authority record) SPF (sender policy framework) SRV (service locator) TXT (text record) Additionally, Amazon Route 53 offers ‘Alias’ records (an Amazon Route 53-specific virtual record). Alias records are used to map resource record sets in your hosted zone to Amazon Elastic Load Balancing load balancers, Amazon CloudFront distributions, AWS Elastic Beanstalk environments, or Amazon S3 buckets that are configured as websites. Alias records work like a CNAME record in that you can map one DNS name (example.com) to another ‘target’ DNS name (elb1234.elb.amazonaws.com). They differ from a CNAME record in that they are not visible to resolvers. Resolvers only see the A record and the resulting IP address of the target record. We anticipate adding additional record types in the future.
* **Q. Are changes to resource record sets transactional?**
  Yes. A transactional change helps ensure that the change is consistent, reliable, and independent of other changes. Amazon Route 53 has been designed so that changes complete entirely on any individual DNS server, or not at all. This helps ensure your DNS queries are always answered consistently, which is important when making changes such as flipping between destination servers. When using the API, each call to ChangeResourceRecordSets returns an identifier that can be used to track the status of the change. Once the status is reported as INSYNC, your change has been performed on all of the Route 53 DNS servers.
* **Q. Can I associate multiple IP addresses with a single record?**
  Yes. Associating multiple IP addresses with a single record is often used for balancing the load of geographically-distributed web servers. Amazon Route 53 allows you to list multiple IP addresses for an A record and responds to DNS requests with the list of all configured IP addresses.
* **Q. Does Amazon Route 53 support DNSSEC?**
  Amazon Route 53 does not support DNSSEC for DNS at this time. But Amazon Route 53 allows DNSSEC on domain registration.
* Route 53 doesn't charge for queries to Alias records that are mapped to a CloudFront distribution. These queries are listed as “Intra-AWS-DNS-Queries” on the Amazon Route 53 usage report.
* **Q. Why does the DNS Query Test Tool return a response different than the dig or nslookup commands?**
  When resource record sets are changed in Amazon Route 53, the service propagates updates you make to your DNS records to its world-wide network of authoritative DNS servers.
* **Q. Does Amazon Route 53 support Weighted Round Robin (WRR)?**
  Yes. Weighted Round Robin allows you to assign weights to resource record sets in order to specify the frequency with which different responses are served. You may want to use this capability to do A/B testing, sending a small portion of traffic to a server on which you’ve made a software change.
* **Q. What is Amazon Route 53's Latency Based Routing (LBR) feature?**
  LBR (Latency Based Routing) is a new feature for Amazon Route 53 that helps you improve your application’s performance for a global audience.
* **Q. Can I have a Geo DNS record for a continent and different Geo DNS records for countries within that continent?**
  Or a Geo DNS record for a country and Geo DNS records for states within that country? Yes, you can have Geo DNS records for overlapping geographic regions (e.g., a continent and countries within that continent, or a country and states within that country). For each end user’s location, Route 53 will return the most specific Geo DNS record that includes that location. In other words, for a given end user’s location, Route 53 will first return a state record; if no state record is found, Route 53 will return a country record; if no country record is found, Route 53 will return a continent record; and finally, if no continent record is found, Route 53 will return the global record.
* **Q. Does Amazon Route 53 support multiple values in response to DNS queries?**
  Route 53 now supports multivalue answers in response to DNS queries. While not a substitute for a load balancer, the ability to return multiple health-checkable IP addresses in response to DNS queries is a way to use DNS to improve availability and load balancing. If you want to route traffic randomly to multiple resources, such as web servers, you can create one multivalue answer record for each resource and, optionally, associate an Amazon Route 53 health check with each record. Amazon Route 53 supports up to eight healthy records in response to each DNS query.
* **Q. What is Amazon Route 53 Traffic Flow?**
  Amazon Route 53 Traffic Flow is an easy-to-use and cost-effective global traffic management service.
* **Q. What is the difference between a traffic policy and a policy record?**
  A traffic policy is the set of rules that you define to route end users’ requests to one of your application’s endpoints. You can create a traffic policy using the visual policy builder in the Amazon Route 53 Traffic Flow section of the Amazon Route 53 console. You can also create traffic policies as JSON-formatted text files and upload these policies using the Route 53 API, the AWS CLI, or the various AWS SDKs. By itself, a traffic policy doesn’t affect how end users are routed to your application because it isn’t yet associated with your application’s DNS name (such as www.example.com). To start using Amazon Route 53 Traffic Flow to route traffic to your application using the traffic policy you’ve created, you create a policy record which associates the traffic policy with the appropriate DNS name within an Amazon Route 53 hosted zone that you own. For example, if you want to use a traffic policy that you’ve named my-first-traffic-policy to manage traffic for your application at www.example.com, you will create a policy record for www.example.com within your hosted zone example.com and choose my-first-traffic-policy as the traffic policy. Policy records are visible in both the Amazon Route 53 Traffic Flow and Amazon Route 53 Hosted Zone sections of the Amazon Route 53 console.
* **Q. Can I use the same policy to manage for more than one DNS name?**
  Yes. You can reuse a policy to manage more than one DNS name in one of two ways. First, you can create additional policy records using the policy. Note that there is an additional charge for using this method, because you are billed for each policy record that you create. The second method is to create one policy record using the policy, and then for each additional DNS name that you want to manage using the policy, you create a standard CNAME record pointing at the DNS name of the policy record that you created. For example, if you create a policy record for example.com, you can then create DNS records for www.example.com, blog.example.com, and www.example.net with a CNAME value of example.com for each record. Note that this method is not possible for records at the zone apex, such as example.net, example.org, or example.co.uk (without www or another subdomain in front of the domain name). For records at the zone apex, you must create a policy record using your traffic policy.
* **Q. Is there a charge for traffic policies that don’t have a policy record?**
  No. We only charge for policy records; there is no charge for creating the traffic policy itself. Q.
* **Q. How do I set up Private DNS?**
  You can set up Private DNS by creating a hosted zone in Route 53, selecting the option to make the hosted zone “private”, and associating the hosted zone with one of your VPCs. After creating the hosted zone, you can associate it with additional VPCs. See the Amazon Route 53 Documentation for full details on how to configure Private DNS.
* **Q. Can I use Private DNS to block domains and DNS names that I don’t want to be reached from within my VPC?**
  Yes, you can block domains and specific DNS names by creating these names in one or more Private DNS hosted zones and pointing these names to your own server (or another location that you manage).
* **Q. What DNS record types can I associate with Route 53 health checks?**
  You can associate any record type supported by Route 53 except SOA and NS records.
* **Q. Can I health check an endpoint if I don’t know its IP address?**
  Yes. You can configure DNS Failover for Elastic Load Balancers and Amazon S3 website buckets via the Amazon Route 53 Console without needing to create a health check of your own. For these endpoint types, Route 53 automatically creates and manages health checks on your behalf which are used when you create an Alias record pointing to the ELB or S3 website bucket and enable the "Evaluate Target Health" parameter on the Alias record. For all other endpoints, you can specify either the DNS name (e.g. www.example.com) or the IP address of the endpoint when you create a health check for that endpoint.
* **Q. If failover occurs and I have multiple healthy endpoints remaining, will Route 53 consider the load on my healthy endpoints when determining where to send traffic from the failed endpoint?**
  No, Route 53 does not make routing decisions based on the load or available traffic capacity of your endpoints. You will need to ensure that you have available capacity at your other endpoints, or the ability to scale at those endpoints, in order to handle the traffic that had been flowing to your failed endpoint.
* **Q. How much load should I expect a health check to generate on my endpoint (for example, a web server)?**
  Each heath check is conducted from multiple locations around the world. The number and set of locations is configurable; you can modify the number of locations from which each of your health checks is conducted using the Amazon Route 53 console or API. Each location checks the endpoint independently at the interval that you select: the default interval of 30 seconds, or an optional fast interval of 10 seconds. Based on the current default number of health checking locations, you should expect your endpoint to receive one request every 2-3 seconds on average for standard interval health checks and one or more requests per second for fast-interval health checks.
* **Q. Do I need to adjust the TTL for my records in order to use DNS Failover?**
  The time for which a DNS resolver caches a response is set by a value called the time to live (TTL) associated with every record. We recommend a TTL of 60 seconds or less when using DNS Failover, to minimize the amount of time it takes for traffic to stop being routed to your failed endpoint. In order to configure DNS Failover for ELB and S3 Website endpoints, you need to use Alias records which have fixed TTL of 60 seconds; for these endpoint types, you do not need to adjust TTLs in order to use DNS Failover.
* **Q. Can I configure a health check on a site accessible only via HTTPS?**
  Yes. Route 53 supports health checks over HTTPS, HTTP or
* **Q. Can I configure a health check on a site accessible only via HTTPS?**
  Yes. Route 53 supports health checks over HTTPS, HTTP or TCP.
* **Q. Do HTTPS health checks support Server Name Indication (SNI)?**
  Yes, HTTPS health checks support SNI.
* The Amazon CloudWatch metrics for all of your Amazon Route 53 health checks are also visible in the Amazon CloudWatch console. Each Amazon CloudWatch metric contains the Health Check ID (for example, 01beb6a3-e1c2-4a2b-a0b7-7031e9060a6a) which you can use to identify which health check the metric is tracking.
* **Q. How can I measure the performance of my application’s endpoints using Amazon Route 53?**
  Amazon Route 53 health checks include an optional latency measurement feature which provides data on how long it takes your endpoint to respond to a request. When you enable the latency measurement feature, the Amazon Route 53 health check will generate additional Amazon CloudWatch metrics showing the time required for Amazon Route 53’s health checkers to establish a connection and to begin receiving data. Amazon Route 53 provides a separate set of latency metrics for each AWS region where Amazon Route 53 health checks are conducted.
* **Q. Can I configure DNS Failover based on internal health metrics, such as CPU load, network, or memory?**
  Yes. Amazon Route 53’s metric based health checks let you perform DNS failover based on any metric that is available within Amazon CloudWatch, including AWS-provided metrics and custom metrics from your own application. When you create a metric based health check within Amazon Route 53, the health check becomes unhealthy whenever its associated Amazon CloudWatch metric enters an alarm state. Metric based health checks are useful to enable DNS failover for endpoints that cannot be reached by a standard Amazon Route 53 health check, such as instances within a Virtual Private Cloud (VPC) that only have private IP addresses. Using Amazon Route 53’s calculated health check feature, you can also accomplish more sophisticated failover scenarios by combining the results of metric based health checks with the results of standard Amazon Route 53 health checks, which make requests against an endpoint from a network of checkers around the world. For example, you can create a configuration which fails away from an endpoint if either its public-facing web page is unavailable, or if internal metrics such as CPU load, network in/out, or disk reads show that the server itself is unhealthy.
* **Q. What name servers are used to register my domain name?**
  When your domain name is created we automatically associate your domain with four unique Route 53 name servers, known as a delegation set. You can view the delegation set for your domain in the Amazon Route 53 console. They're listed in the hosted zone that we create for you automatically when you register a domain. By default, Route 53 will assign a new, unique delegation set for each hosted zone you create. However, you can also use the Route 53 API to create a “reusable delegation set”, which you can then apply to multiple hosted zones that you create. For customers with large numbers of domain names, reusable delegation sets make migration to Route 53 simple, because you can instruct your domain name registrar to use the same delegation set for all your domains managed by Route 53. This feature also makes it possible for you to create “white label” name server addresses such as ns1.example.com, ns2.example.com, etc., which you can point to your Route 53 name servers. You can then use your “white label” name server addresses as the authoritative name servers for as many of your domain names as desired. For more details, see the Amazon Route 53 documentation
* **Q. Can I transfer my .com and .net domain registrations from Gandi to Amazon?**
  No. We plan to add this functionality soon.
* **Q. How do I transfer my existing domain name registration to Amazon Route 53 without disrupting my existing web traffic?**
  First, you need to get a list of the DNS record data for your domain name, generally available in the form of a “zone file” that you can get from your existing DNS provider. With the DNS record data in hand, you can use Route 53’s Management Console or simple web-services interface to create a hosted zone that can store the DNS records for your domain name and follow its transfer process, which will include such steps as updating the name servers for your domain name to the ones associated with your hosted zone. To complete the domain name transfer process, contact the registrar with whom you registered your domain name and follow its transfer process, which will include steps such as updating the name servers for your domain name to the ones associated with your hosted zone. As soon as your registrar propagates the new name server delegations, the DNS queries from your end users will start to get answered by the Route 53 DNS servers.
* **Q. Is there a limit to the number of domains I can manage using Amazon Route 53?** Each new Amazon Route 53 account is limited to a maximum of 50 domains. Complete our request form for a higher limit and we will respond to your request within two business days.
* **Q. How do I transfer a domain registration that has DNSSEC enabled to Amazon Route 53?**
  See our documentation for a step-by-step guide on transferring your DNSSEC-enabled domain to Amazon Route 53.

The End